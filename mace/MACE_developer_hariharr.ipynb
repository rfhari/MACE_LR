{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCup0m-0kKuo"
   },
   "source": [
    "## Install MACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XW28dp7ajW-6",
    "outputId": "e6ba26f3-80f5-41c5-d4bc-a9555cb092f9"
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# if test -d mace\n",
    "# then\n",
    "#     rm -rfv mace\n",
    "# fi\n",
    "# git clone --depth 1 --branch develop https://github.com/ACEsuit/mace.git \n",
    "# pip install mace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 949
    },
    "id": "Mw0A5LHnjpS6",
    "outputId": "7b6fbf59-aea3-4b62-bff7-b25e69c84281"
   },
   "outputs": [],
   "source": [
    "# !pip install mace/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "\n",
    "We will first create a model that we will dissect afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EqGr9Qz-lWaB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "from e3nn import o3\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mace import data, modules, tools\n",
    "from mace.tools import torch_geometric\n",
    "# from mace.modules.models_hariharr_dipole import *\n",
    "# from mace.modules.models_hariharr_energy import *\n",
    "from mace.modules.models_hariharr_energy_ewald import *\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_irreps: 32x0e+32x1o [32]\n",
      "target_irreps in EquivariantProductBasisBlock: 32x0e+32x1o\n",
      "interaction: 0 hidden_irreps: 32x0e [32, 32]\n",
      "target_irreps in EquivariantProductBasisBlock: 32x0e\n"
     ]
    }
   ],
   "source": [
    "z_table = tools.AtomicNumberTable([1, 8])\n",
    "atomic_energies = np.array([-1.0, -3.0], dtype=float)\n",
    "cutoff = 3\n",
    "\n",
    "ewald_hyperparams = dict(\n",
    "      k_cutoff = 0.6,                           # Frequency cutoff [Å^-1]\n",
    "      delta_k = 0.2,                            # Voxel grid resolution [Å^-1]\n",
    "      num_k_rbf = 128,                          # Gaussian radial basis size (Fourier filter)\n",
    "      downprojection_size = 8,                  # Size of linear bottleneck layer\n",
    "      num_hidden = 0,                           # Number of residuals in update function\n",
    "      num_k_x = 1, #check: what is num_kx, num_ky, num_kz mean\n",
    "      num_k_y = 1,\n",
    "      num_k_z = 3,\n",
    "    )\n",
    "\n",
    "model_config = dict(\n",
    "        num_elements=2,  # number of chemical elements\n",
    "        atomic_energies=atomic_energies,  # atomic energies used for normalisation\n",
    "        avg_num_neighbors=8,  # check: maybe this should be increased. Avg number of neighbours of the atoms, used for internal normalisation of messages\n",
    "        atomic_numbers=z_table.zs,  # atomic numbers, used to specify chemical element embeddings of the model\n",
    "        r_max=cutoff,  # cutoff\n",
    "        num_bessel=8,  # number of radial features\n",
    "        num_polynomial_cutoff=6,  # smoothness of the radial cutoff\n",
    "        max_ell=2,  # expansion order of spherical harmonic adge attributes\n",
    "        num_interactions=2,  # number of layers, typically 2\n",
    "        interaction_cls_first=modules.interaction_classes[\n",
    "            \"RealAgnosticResidualInteractionBlock\"\n",
    "        ],  # interation block of first layer\n",
    "        interaction_cls=modules.interaction_classes[\n",
    "            \"RealAgnosticResidualInteractionBlock\"\n",
    "        ],  # interaction block of subsequent layers\n",
    "        hidden_irreps=o3.Irreps(\"32x0e + 32x1o\"),  # 32: number of embedding channels, 0e, 1o is specifying which equivariant messages to use. Here up to L_max=1\n",
    "        correlation=3,  # correlation order of the messages (body order - 1)\n",
    "        MLP_irreps=o3.Irreps(\"16x0e\"),  # number of hidden dimensions of last layer readout MLP\n",
    "        gate=torch.nn.functional.silu,  # nonlinearity used in last layer readout MLP\n",
    "        ewald_hyperparams = ewald_hyperparams,\n",
    "        use_pbc=True,\n",
    "    )\n",
    "\n",
    "model = TestMACE_Ewald(**model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42-l41XanAv2",
    "outputId": "4b52ee17-8acd-4eef-e22b-1c4a0776a064"
   },
   "outputs": [],
   "source": [
    "# z_table = tools.AtomicNumberTable([1, 8])\n",
    "# atomic_energies = np.array([-1.0, -3.0], dtype=float)\n",
    "# cutoff = 3\n",
    "\n",
    "# model_config = dict(\n",
    "#         num_elements=2,  # number of chemical elements\n",
    "#         atomic_energies=atomic_energies,  # atomic energies used for normalisation\n",
    "#         avg_num_neighbors=8,  # avg number of neighbours of the atoms, used for internal normalisation of messages\n",
    "#         atomic_numbers=z_table.zs,  # atomic numbers, used to specify chemical element embeddings of the model\n",
    "#         r_max=cutoff,  # cutoff\n",
    "#         num_bessel=8,  # number of radial features\n",
    "#         num_polynomial_cutoff=6,  # smoothness of the radial cutoff\n",
    "#         max_ell=2,  # expansion order of spherical harmonic adge attributes\n",
    "#         num_interactions=2,  # number of layers, typically 2\n",
    "#         interaction_cls_first=modules.interaction_classes[\n",
    "#             \"RealAgnosticResidualInteractionBlock\"\n",
    "#         ],  # interation block of first layer\n",
    "#         interaction_cls=modules.interaction_classes[\n",
    "#             \"RealAgnosticResidualInteractionBlock\"\n",
    "#         ],  # interaction block of subsequent layers\n",
    "#         hidden_irreps=o3.Irreps(\"32x0e + 32x1o\"),  # 32: number of embedding channels, 0e, 1o is specifying which equivariant messages to use. Here up to L_max=1\n",
    "#         correlation=3,  # correlation order of the messages (body order - 1)\n",
    "#         MLP_irreps=o3.Irreps(\"16x0e\"),  # number of hidden dimensions of last layer readout MLP\n",
    "#         gate=torch.nn.functional.silu,  # nonlinearity used in last layer readout MLP\n",
    "#     )\n",
    "\n",
    "# model = TestMACE(**model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff = 3\n",
    "# num_bessel = 8\n",
    "# num_polynomial_cutoff = 6\n",
    "# max_ell = 2\n",
    "# num_interactions = 4\n",
    "# num_elements = 2\n",
    "# MLP_irreps = o3.Irreps(\"16x0e\")\n",
    "# hidden_irreps = o3.Irreps(\"32x0e + 32x1o\")\n",
    "# MLP_irreps = o3.Irreps(\"16x0e\")\n",
    "# avg_num_neighbors = 8\n",
    "# z_table = tools.AtomicNumberTable([1, 8])\n",
    "# atomic_energies = np.array([-1.0, -3.0], dtype=float)\n",
    "# correlation = 3\n",
    "# gate = torch.nn.functional.silu\n",
    "\n",
    "\n",
    "# model = TestEnergyDipolesMACE(\n",
    "#     r_max=cutoff,\n",
    "#     num_bessel=num_bessel,\n",
    "#     num_polynomial_cutoff=num_polynomial_cutoff,\n",
    "#     max_ell=max_ell,\n",
    "#     interaction_cls=modules.interaction_classes[\n",
    "#             \"RealAgnosticResidualInteractionBlock\"\n",
    "#         ],\n",
    "#     interaction_cls_first=modules.interaction_classes[\n",
    "#             \"RealAgnosticResidualInteractionBlock\"\n",
    "#         ],\n",
    "#     num_interactions=num_interactions,\n",
    "#     num_elements=num_elements,\n",
    "#     hidden_irreps=hidden_irreps,\n",
    "#     MLP_irreps=MLP_irreps,\n",
    "#     avg_num_neighbors=avg_num_neighbors,\n",
    "#     atomic_numbers=z_table.zs,\n",
    "#     correlation=correlation,\n",
    "#     gate=gate,\n",
    "#     atomic_energies=atomic_energies\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wZK0mufovQU",
    "outputId": "36d03aba-0d99-4389-dbbc-abace02bc9ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestMACE_Ewald(\n",
      "  (down): Dense(\n",
      "    (linear): Linear(in_features=31, out_features=8, bias=False)\n",
      "    (_activation): Identity()\n",
      "  )\n",
      "  (ewald_blocks): ModuleList(\n",
      "    (0-1): 2 x EwaldBlock(\n",
      "      (down): Dense(\n",
      "        (linear): Linear(in_features=31, out_features=8, bias=False)\n",
      "        (_activation): Identity()\n",
      "      )\n",
      "      (up): Dense(\n",
      "        (linear): Linear(in_features=8, out_features=32, bias=False)\n",
      "        (_activation): Identity()\n",
      "      )\n",
      "      (pre_residual): ResidualLayer(\n",
      "        (dense_mlp): Sequential(\n",
      "          (0): Dense(\n",
      "            (linear): Linear(in_features=32, out_features=32, bias=False)\n",
      "            (_activation): ScaledSiLU(\n",
      "              (_activation): SiLU()\n",
      "            )\n",
      "          )\n",
      "          (1): Dense(\n",
      "            (linear): Linear(in_features=32, out_features=32, bias=False)\n",
      "            (_activation): ScaledSiLU(\n",
      "              (_activation): SiLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (ewald_layers): ModuleList(\n",
      "        (0): Dense(\n",
      "          (linear): Linear(in_features=32, out_features=32, bias=False)\n",
      "          (_activation): ScaledSiLU(\n",
      "            (_activation): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (node_embedding): LinearNodeEmbeddingBlock(\n",
      "    (linear): Linear(2x0e -> 32x0e | 64 weights)\n",
      "  )\n",
      "  (radial_embedding): RadialEmbeddingBlock(\n",
      "    (bessel_fn): BesselBasis(r_max=3.0, num_basis=8, trainable=False)\n",
      "    (cutoff_fn): PolynomialCutoff(p=6.0, r_max=3.0)\n",
      "  )\n",
      "  (spherical_harmonics): SphericalHarmonics()\n",
      "  (atomic_energies_fn): AtomicEnergiesBlock(energies=[-1.0000, -3.0000])\n",
      "  (interactions): ModuleList(\n",
      "    (0): RealAgnosticResidualInteractionBlock(\n",
      "      (linear_up): Linear(32x0e -> 32x0e | 1024 weights)\n",
      "      (conv_tp): TensorProduct(32x0e x 1x0e+1x1o+1x2e -> 32x0e+32x1o+32x2e | 96 paths | 96 weights)\n",
      "      (conv_tp_weights): FullyConnectedNet[8, 64, 64, 64, 96]\n",
      "      (linear): Linear(32x0e+32x1o+32x2e -> 32x0e+32x1o+32x2e | 3072 weights)\n",
      "      (skip_tp): FullyConnectedTensorProduct(32x0e x 2x0e -> 32x0e+32x1o | 2048 paths | 2048 weights)\n",
      "      (reshape): reshape_irreps()\n",
      "    )\n",
      "    (1): RealAgnosticResidualInteractionBlock(\n",
      "      (linear_up): Linear(32x0e+32x1o -> 32x0e+32x1o | 2048 weights)\n",
      "      (conv_tp): TensorProduct(32x0e+32x1o x 1x0e+1x1o+1x2e -> 64x0e+96x1o+64x2e | 224 paths | 224 weights)\n",
      "      (conv_tp_weights): FullyConnectedNet[8, 64, 64, 64, 224]\n",
      "      (linear): Linear(64x0e+96x1o+64x2e -> 32x0e+32x1o+32x2e | 7168 weights)\n",
      "      (skip_tp): FullyConnectedTensorProduct(32x0e+32x1o x 2x0e -> 32x0e | 2048 paths | 2048 weights)\n",
      "      (reshape): reshape_irreps()\n",
      "    )\n",
      "  )\n",
      "  (products): ModuleList(\n",
      "    (0): EquivariantProductBasisBlock(\n",
      "      (symmetric_contractions): SymmetricContraction(\n",
      "        (contractions): ModuleList(\n",
      "          (0): Contraction(\n",
      "            (contractions_weighting): ModuleList(\n",
      "              (0-1): 2 x GraphModule()\n",
      "            )\n",
      "            (contractions_features): ModuleList(\n",
      "              (0-1): 2 x GraphModule()\n",
      "            )\n",
      "            (weights): ParameterList(\n",
      "                (0): Parameter containing: [torch.float32 of size 2x3x32]\n",
      "                (1): Parameter containing: [torch.float32 of size 2x1x32]\n",
      "            )\n",
      "            (graph_opt_main): GraphModule()\n",
      "          )\n",
      "          (1): Contraction(\n",
      "            (contractions_weighting): ModuleList(\n",
      "              (0-1): 2 x GraphModule()\n",
      "            )\n",
      "            (contractions_features): ModuleList(\n",
      "              (0-1): 2 x GraphModule()\n",
      "            )\n",
      "            (weights): ParameterList(\n",
      "                (0): Parameter containing: [torch.float32 of size 2x4x32]\n",
      "                (1): Parameter containing: [torch.float32 of size 2x1x32]\n",
      "            )\n",
      "            (graph_opt_main): GraphModule()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (linear): Linear(32x0e+32x1o -> 32x0e+32x1o | 2048 weights)\n",
      "    )\n",
      "    (1): EquivariantProductBasisBlock(\n",
      "      (symmetric_contractions): SymmetricContraction(\n",
      "        (contractions): ModuleList(\n",
      "          (0): Contraction(\n",
      "            (contractions_weighting): ModuleList(\n",
      "              (0-1): 2 x GraphModule()\n",
      "            )\n",
      "            (contractions_features): ModuleList(\n",
      "              (0-1): 2 x GraphModule()\n",
      "            )\n",
      "            (weights): ParameterList(\n",
      "                (0): Parameter containing: [torch.float32 of size 2x3x32]\n",
      "                (1): Parameter containing: [torch.float32 of size 2x1x32]\n",
      "            )\n",
      "            (graph_opt_main): GraphModule()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (linear): Linear(32x0e -> 32x0e | 1024 weights)\n",
      "    )\n",
      "  )\n",
      "  (readouts): ModuleList(\n",
      "    (0): LinearReadoutBlock(\n",
      "      (linear): Linear(32x0e+32x1o -> 1x0e | 32 weights)\n",
      "    )\n",
      "    (1): NonLinearReadoutBlock(\n",
      "      (linear_1): Linear(32x0e -> 16x0e | 512 weights)\n",
      "      (non_linearity): Activation [x] (16x0e -> 16x0e)\n",
      "      (linear_2): Linear(16x0e -> 1x0e | 16 weights)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vYMQTAfrodDI"
   },
   "source": [
    "create water molecule for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88r1ZNfkojNB",
    "outputId": "1a366585-6d3c-4487-d1e3-a2b65326d6e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pbc: (True, True, True)\n",
      "The data is stored in batches. Each batch is a single graph, potentially made up of several disjointed sub-graphs corresponding to different chemical structures. \n",
      "Batch(batch=[3], cell=[3, 3], edge_index=[2, 834], energy=[1], energy_weight=[1], forces=[3, 3], forces_weight=[1], node_attrs=[3, 2], positions=[3, 3], ptr=[2], shifts=[834, 3], stress_weight=[1], unit_shifts=[834, 3], virials_weight=[1], weight=[1])\n",
      "\n",
      "batch.edge_index contains which atoms are connected within the cutoff. It is the adjacency matrix in sparse format.\n",
      "\n",
      "tensor([[0, 0, 0,  ..., 2, 2, 2],\n",
      "        [0, 1, 2,  ..., 0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "config = data.Configuration(\n",
    "    atomic_numbers=np.array([8, 1, 1]),\n",
    "    positions=np.array(\n",
    "        [\n",
    "            [0.0, -2.0, 0.0],\n",
    "            [1.0, 0.0, 0.0],\n",
    "            [0.0, 1.0, 0.0],\n",
    "        ]\n",
    "    ),\n",
    "    forces=np.array(\n",
    "        [\n",
    "            [0.0, -1.3, 0.0],\n",
    "            [1.0, 0.2, 0.0],\n",
    "            [0.0, 1.1, 0.3],\n",
    "        ]\n",
    "    ),\n",
    "    energy=-1.5,\n",
    "    pbc=(True, True, True),\n",
    ")\n",
    "\n",
    "atomic_data = data.AtomicData.from_config(config, z_table=z_table, cutoff=float(model.r_max))\n",
    "data_loader = torch_geometric.dataloader.DataLoader(\n",
    "        dataset=[atomic_data],\n",
    "        batch_size=3,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "batch = next(iter(data_loader))\n",
    "print(\"The data is stored in batches. Each batch is a single graph, potentially made up of several disjointed sub-graphs corresponding to different chemical structures. \")\n",
    "print(batch)\n",
    "print(\"\\nbatch.edge_index contains which atoms are connected within the cutoff. It is the adjacency matrix in sparse format.\\n\")\n",
    "print(batch.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pbc: (True, True, True)\n",
      "The data is stored in batches. Each batch is a single graph, potentially made up of several disjointed sub-graphs corresponding to different chemical structures. \n",
      "Batch(batch=[3], cell=[3, 3], edge_index=[2, 834], energy=[1], energy_weight=[1], forces=[3, 3], forces_weight=[1], node_attrs=[3, 2], positions=[3, 3], ptr=[2], shifts=[834, 3], stress_weight=[1], unit_shifts=[834, 3], virials_weight=[1], weight=[1])\n",
      "\n",
      "batch.edge_index contains which atoms are connected within the cutoff. It is the adjacency matrix in sparse format.\n",
      "\n",
      "tensor([[0, 0, 0,  ..., 2, 2, 2],\n",
      "        [0, 1, 2,  ..., 0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "config = data.Configuration(\n",
    "    atomic_numbers=np.array([8, 1, 1]),\n",
    "    positions=np.array(\n",
    "        [\n",
    "            [0.0, -2.0, 0.0],\n",
    "            [1.0, 0.0, 0.0],\n",
    "            [0.0, 1.0, 0.0],\n",
    "        ]\n",
    "    ),\n",
    "    forces=np.array(\n",
    "        [\n",
    "            [0.0, -1.3, 0.0],\n",
    "            [1.0, 0.2, 0.0],\n",
    "            [0.0, 1.1, 0.3],\n",
    "        ]\n",
    "    ),\n",
    "    energy=-1.5,\n",
    "    pbc=(True, True, True),\n",
    ")\n",
    "\n",
    "atomic_data = data.AtomicData.from_config(config, z_table=z_table, cutoff=float(model.r_max))\n",
    "data_loader = torch_geometric.dataloader.DataLoader(\n",
    "        dataset=[atomic_data],\n",
    "        batch_size=3,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "batch = next(iter(data_loader))\n",
    "print(\"The data is stored in batches. Each batch is a single graph, potentially made up of several disjointed sub-graphs corresponding to different chemical structures. \")\n",
    "print(batch)\n",
    "print(\"\\nbatch.edge_index contains which atoms are connected within the cutoff. It is the adjacency matrix in sparse format.\\n\")\n",
    "print(batch.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch.cell\n",
    "cells = batch.cell\n",
    "cells[:, 2] # torch.cross(cells[:, 1], cells[:, 2], dim=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACE Forward      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type: <class 'mace.tools.torch_geometric.batch.Batch'>\n",
      "cross_a2a3: torch.Size([3])\n",
      "cross_a3a1: torch.Size([3])\n",
      "cross_a1a2: torch.Size([3])\n",
      "bcells: torch.Size([3, 3]) vol: torch.Size([1])\n",
      "k_grid shape if periodic: torch.Size([1, 31, 3])\n",
      "k_index_product_set shape if periodic: torch.Size([31, 3])\n",
      "k_cell shape if periodic: torch.Size([3, 3])\n",
      "self.slice_indices: [32, 32]\n",
      "node_feats: torch.Size([3, 32])\n",
      "interaction layer: 0\n",
      "from ewald block b: torch.Size([3, 31, 3]) from ewald block k: torch.Size([1, 31, 3])\n",
      "interaction layer: 0 node feats after ewald: torch.Size([3, 32])\n",
      "interaction layer: 0 node feats after MACE: torch.Size([3, 128])\n",
      "interaction layer: 0 node_feats inside interaction: torch.Size([3, 128])\n",
      "interaction layer: 1\n",
      "interaction layer: 1 node feats after ewald: torch.Size([3, 32])\n",
      "interaction layer: 1 node feats after MACE: torch.Size([3, 32])\n",
      "interaction layer: 1 node_feats inside interaction: torch.Size([3, 32])\n"
     ]
    }
   ],
   "source": [
    "data = batch\n",
    "training = False,\n",
    "compute_force = True,\n",
    "compute_virials = False,\n",
    "compute_stress = False,\n",
    "compute_displacement = False,\n",
    "\n",
    "outputs = model.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGpLz7gXzAz0",
    "outputId": "0f4e8065-46cb-43c3-bd7c-bc2c2698913f"
   },
   "outputs": [],
   "source": [
    "# energy = scatter_sum(\n",
    "#                 src=node_energies, index=batch[\"batch\"], dim=-1, dim_size=batch.num_graphs\n",
    "#             )  # [n_graphs,]\n",
    "# # in the code this step is done for each layer followed by summing the layer-wise output\n",
    "# print(\"Energy:\",energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(batch=[3], cell=[3, 3], edge_index=[2, 834], energy=[1], energy_weight=[1], forces=[3, 3], forces_weight=[1], node_attrs=[3, 2], positions=[3, 3], ptr=[2], shifts=[834, 3], stress_weight=[1], unit_shifts=[834, 3], virials_weight=[1], weight=[1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
