{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A deep dive in the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you will do a dive into the `MACE` code, which is a highly accurate and efficient MLIP. If you would like to understand this method in more detail, you can find the [original method paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/4a36c3c51af11ed9f34615b81edb5bbc-Paper-Conference.pdf). MACE is a Message Passing Neural Network (MPNNs) Interatomic Potential that forms equivariant many body messages.\n",
    "\n",
    "MACE was developed by unifying the Atomic Cluster Expansion (ACE) approach with the equivariant MPNNs. The mathematical formalism which unifies these methods is explained in the [accompaning paper](https://doi.org/10.48550/arXiv.2205.06643). Another [useful reference](https://doi.org/10.48550/arXiv.2305.14247) showcases the methods performance on published benchmark datasets aswell as updated set of equations that we will follow in this notebook.  The [code implementation](https://github.com/ACEsuit/mace) is publically available and [here](https://mace-docs.readthedocs.io/en/latest/) you can find the accompaning documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCup0m-0kKuo"
   },
   "source": [
    "## Install MACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XW28dp7ajW-6",
    "outputId": "e6ba26f3-80f5-41c5-d4bc-a9555cb092f9"
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# if test -d mace\n",
    "# then\n",
    "#     rm -rfv mace\n",
    "# fi\n",
    "# git clone --depth 1 --branch develop https://github.com/ACEsuit/mace.git \n",
    "# pip install mace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 949
    },
    "id": "Mw0A5LHnjpS6",
    "outputId": "7b6fbf59-aea3-4b62-bff7-b25e69c84281"
   },
   "outputs": [],
   "source": [
    "# !pip install mace/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "\n",
    "We will first create a model that we will dissect afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EqGr9Qz-lWaB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "from e3nn import o3\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mace import data, modules, tools\n",
    "from mace.tools import torch_geometric\n",
    "# from mace.modules.models_hariharr_dipole import *\n",
    "# from mace.modules.models_hariharr_energy import *\n",
    "from mace.modules.models_hariharr_energy_ewald import *\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'num_k_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 36\u001b[0m\n\u001b[1;32m      5\u001b[0m ewald_hyperparams \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m      6\u001b[0m       k_cutoff \u001b[39m=\u001b[39m \u001b[39m0.6\u001b[39m,                           \u001b[39m# Frequency cutoff [Å^-1]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m       delta_k \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m,                            \u001b[39m# Voxel grid resolution [Å^-1]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m       num_hidden \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,                           \u001b[39m# Number of residuals in update function\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     13\u001b[0m model_config \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m     14\u001b[0m         num_elements\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,  \u001b[39m# number of chemical elements\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         atomic_energies\u001b[39m=\u001b[39matomic_energies,  \u001b[39m# atomic energies used for normalisation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m         ewald_hyperparams \u001b[39m=\u001b[39m ewald_hyperparams,\n\u001b[1;32m     34\u001b[0m     )\n\u001b[0;32m---> 36\u001b[0m model \u001b[39m=\u001b[39m TestMACE_Ewald(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_config)\n",
      "File \u001b[0;32m~/Desktop/MACE_exploration_backup/mace/mace/modules/models_hariharr_energy_ewald.py:80\u001b[0m, in \u001b[0;36mTestMACE_Ewald.__init__\u001b[0;34m(self, r_max, num_bessel, num_polynomial_cutoff, max_ell, interaction_cls, interaction_cls_first, num_interactions, num_elements, hidden_irreps, MLP_irreps, atomic_energies, avg_num_neighbors, atomic_numbers, correlation, gate, radial_MLP, radial_type, ewald_hyperparams, atom_to_atom_cutoff, use_pbc)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_ewald:\n\u001b[1;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_pbc:\n\u001b[1;32m     79\u001b[0m         \u001b[39m# Integer values to define box of k-lattice indices\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_k_x \u001b[39m=\u001b[39m ewald_hyperparams[\u001b[39m\"\u001b[39;49m\u001b[39mnum_k_x\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     81\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_k_y \u001b[39m=\u001b[39m ewald_hyperparams[\u001b[39m\"\u001b[39m\u001b[39mnum_k_y\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     82\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_k_z \u001b[39m=\u001b[39m ewald_hyperparams[\u001b[39m\"\u001b[39m\u001b[39mnum_k_z\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num_k_x'"
     ]
    }
   ],
   "source": [
    "z_table = tools.AtomicNumberTable([1, 8])\n",
    "atomic_energies = np.array([-1.0, -3.0], dtype=float)\n",
    "cutoff = 3\n",
    "\n",
    "ewald_hyperparams = dict(\n",
    "      k_cutoff = 0.6,                           # Frequency cutoff [Å^-1]\n",
    "      delta_k = 0.2,                            # Voxel grid resolution [Å^-1]\n",
    "      num_k_rbf = 128,                          # Gaussian radial basis size (Fourier filter)\n",
    "      downprojection_size = 8,                  # Size of linear bottleneck layer\n",
    "      num_hidden = 0,                           # Number of residuals in update function\n",
    "    )\n",
    "\n",
    "model_config = dict(\n",
    "        num_elements=2,  # number of chemical elements\n",
    "        atomic_energies=atomic_energies,  # atomic energies used for normalisation\n",
    "        avg_num_neighbors=8,  # avg number of neighbours of the atoms, used for internal normalisation of messages\n",
    "        atomic_numbers=z_table.zs,  # atomic numbers, used to specify chemical element embeddings of the model\n",
    "        r_max=cutoff,  # cutoff\n",
    "        num_bessel=8,  # number of radial features\n",
    "        num_polynomial_cutoff=6,  # smoothness of the radial cutoff\n",
    "        max_ell=2,  # expansion order of spherical harmonic adge attributes\n",
    "        num_interactions=2,  # number of layers, typically 2\n",
    "        interaction_cls_first=modules.interaction_classes[\n",
    "            \"RealAgnosticResidualInteractionBlock\"\n",
    "        ],  # interation block of first layer\n",
    "        interaction_cls=modules.interaction_classes[\n",
    "            \"RealAgnosticResidualInteractionBlock\"\n",
    "        ],  # interaction block of subsequent layers\n",
    "        hidden_irreps=o3.Irreps(\"32x0e + 32x1o\"),  # 32: number of embedding channels, 0e, 1o is specifying which equivariant messages to use. Here up to L_max=1\n",
    "        correlation=3,  # correlation order of the messages (body order - 1)\n",
    "        MLP_irreps=o3.Irreps(\"16x0e\"),  # number of hidden dimensions of last layer readout MLP\n",
    "        gate=torch.nn.functional.silu,  # nonlinearity used in last layer readout MLP\n",
    "        ewald_hyperparams = ewald_hyperparams,\n",
    "    )\n",
    "\n",
    "model = TestMACE_Ewald(**model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42-l41XanAv2",
    "outputId": "4b52ee17-8acd-4eef-e22b-1c4a0776a064"
   },
   "outputs": [],
   "source": [
    "# z_table = tools.AtomicNumberTable([1, 8])\n",
    "# atomic_energies = np.array([-1.0, -3.0], dtype=float)\n",
    "# cutoff = 3\n",
    "\n",
    "# model_config = dict(\n",
    "#         num_elements=2,  # number of chemical elements\n",
    "#         atomic_energies=atomic_energies,  # atomic energies used for normalisation\n",
    "#         avg_num_neighbors=8,  # avg number of neighbours of the atoms, used for internal normalisation of messages\n",
    "#         atomic_numbers=z_table.zs,  # atomic numbers, used to specify chemical element embeddings of the model\n",
    "#         r_max=cutoff,  # cutoff\n",
    "#         num_bessel=8,  # number of radial features\n",
    "#         num_polynomial_cutoff=6,  # smoothness of the radial cutoff\n",
    "#         max_ell=2,  # expansion order of spherical harmonic adge attributes\n",
    "#         num_interactions=2,  # number of layers, typically 2\n",
    "#         interaction_cls_first=modules.interaction_classes[\n",
    "#             \"RealAgnosticResidualInteractionBlock\"\n",
    "#         ],  # interation block of first layer\n",
    "#         interaction_cls=modules.interaction_classes[\n",
    "#             \"RealAgnosticResidualInteractionBlock\"\n",
    "#         ],  # interaction block of subsequent layers\n",
    "#         hidden_irreps=o3.Irreps(\"32x0e + 32x1o\"),  # 32: number of embedding channels, 0e, 1o is specifying which equivariant messages to use. Here up to L_max=1\n",
    "#         correlation=3,  # correlation order of the messages (body order - 1)\n",
    "#         MLP_irreps=o3.Irreps(\"16x0e\"),  # number of hidden dimensions of last layer readout MLP\n",
    "#         gate=torch.nn.functional.silu,  # nonlinearity used in last layer readout MLP\n",
    "#     )\n",
    "\n",
    "# model = TestMACE(**model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff = 3\n",
    "# num_bessel = 8\n",
    "# num_polynomial_cutoff = 6\n",
    "# max_ell = 2\n",
    "# num_interactions = 4\n",
    "# num_elements = 2\n",
    "# MLP_irreps = o3.Irreps(\"16x0e\")\n",
    "# hidden_irreps = o3.Irreps(\"32x0e + 32x1o\")\n",
    "# MLP_irreps = o3.Irreps(\"16x0e\")\n",
    "# avg_num_neighbors = 8\n",
    "# z_table = tools.AtomicNumberTable([1, 8])\n",
    "# atomic_energies = np.array([-1.0, -3.0], dtype=float)\n",
    "# correlation = 3\n",
    "# gate = torch.nn.functional.silu\n",
    "\n",
    "\n",
    "# model = TestEnergyDipolesMACE(\n",
    "#     r_max=cutoff,\n",
    "#     num_bessel=num_bessel,\n",
    "#     num_polynomial_cutoff=num_polynomial_cutoff,\n",
    "#     max_ell=max_ell,\n",
    "#     interaction_cls=modules.interaction_classes[\n",
    "#             \"RealAgnosticResidualInteractionBlock\"\n",
    "#         ],\n",
    "#     interaction_cls_first=modules.interaction_classes[\n",
    "#             \"RealAgnosticResidualInteractionBlock\"\n",
    "#         ],\n",
    "#     num_interactions=num_interactions,\n",
    "#     num_elements=num_elements,\n",
    "#     hidden_irreps=hidden_irreps,\n",
    "#     MLP_irreps=MLP_irreps,\n",
    "#     avg_num_neighbors=avg_num_neighbors,\n",
    "#     atomic_numbers=z_table.zs,\n",
    "#     correlation=correlation,\n",
    "#     gate=gate,\n",
    "#     atomic_energies=atomic_energies\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wZK0mufovQU",
    "outputId": "36d03aba-0d99-4389-dbbc-abace02bc9ba"
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYMQTAfrodDI"
   },
   "source": [
    "We should also create a graph object of a dummy water molecule for demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88r1ZNfkojNB",
    "outputId": "1a366585-6d3c-4487-d1e3-a2b65326d6e1"
   },
   "outputs": [],
   "source": [
    "config = data.Configuration(\n",
    "    atomic_numbers=np.array([8, 1, 1]),\n",
    "    positions=np.array(\n",
    "        [\n",
    "            [0.0, -2.0, 0.0],\n",
    "            [1.0, 0.0, 0.0],\n",
    "            [0.0, 1.0, 0.0],\n",
    "        ]\n",
    "    ),\n",
    "    forces=np.array(\n",
    "        [\n",
    "            [0.0, -1.3, 0.0],\n",
    "            [1.0, 0.2, 0.0],\n",
    "            [0.0, 1.1, 0.3],\n",
    "        ]\n",
    "    ),\n",
    "    energy=-1.5,\n",
    ")\n",
    "\n",
    "atomic_data = data.AtomicData.from_config(config, z_table=z_table, cutoff=float(model.r_max))\n",
    "data_loader = torch_geometric.dataloader.DataLoader(\n",
    "        dataset=[atomic_data],\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "batch = next(iter(data_loader))\n",
    "print(\"The data is stored in batches. Each batch is a single graph, potentially made up of several disjointed sub-graphs corresponding to different chemical structures. \")\n",
    "print(batch)\n",
    "print(\"\\nbatch.edge_index contains which atoms are connected within the cutoff. It is the adjacency matrix in sparse format.\\n\")\n",
    "print(batch.edge_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACE Forward      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = batch\n",
    "training = False,\n",
    "compute_force = True,\n",
    "compute_virials = False,\n",
    "compute_stress = False,\n",
    "compute_displacement = False,\n",
    "\n",
    "outputs = model.forward(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amYfG_QdkRvc"
   },
   "source": [
    "# A deep dive in the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhvaTiHgkjV9"
   },
   "source": [
    "## The embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F14vwxN2e_GK"
   },
   "source": [
    "### Spherical Harmonics\n",
    "The real spherical harmonics expand the angular degree of freedom in a basis that are index by $lm$ indices. We describe the angular part as a unit vector $\\hat{r}_{ij} := \\frac{r_{i} - r_{j}}{||r_{i} - r_{j}||_{2}}$ and the spherical harmonics are defined as polynomial functions of $\\hat{r}$ that are orthonormal.\n",
    "\n",
    "Let's first create a random set of points on the unit sphere and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "rjFXAZ1vkWAo",
    "outputId": "32826e72-849e-40ac-e6c4-8cc109eff84c"
   },
   "outputs": [],
   "source": [
    "# create random set of points on the unit sphere and plot them\n",
    "n = 200\n",
    "points = torch.randn(n, 3)\n",
    "points = points / points.norm(dim=-1, keepdim=True)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(points[:, 0], points[:, 1], points[:, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOXwTS_Se45h"
   },
   "source": [
    "The order of the expansion in controlled by $l_{\\text{max}}$ and the number of basis functions is $(l_{\\text{max}} + 1)^{2}$. Let's see what $l_{\\text{max}}$ is used in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bT_mzos2fDro",
    "outputId": "4710a46d-c9ec-452f-c574-20882fbf189e"
   },
   "outputs": [],
   "source": [
    "l_max = model.spherical_harmonics._lmax\n",
    "print(\"l_max =\",l_max)\n",
    "# It should return 2 for the example model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PRgy0y1fE5Z"
   },
   "source": [
    "One important aspect of spherical harmonics is their normalization. In MACE, we use the **component** normalization satisfying:\n",
    "$$||Y_{l}||^{2} = 2l + 1$$\n",
    "Let's pass now the points to the spherical harmonics and check the normalization and the shape.\n",
    "In the model's code, the unit vectors expanded in the spherical harmonics basis are named **edge_attrs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZZTTz21fL7a",
    "outputId": "ae0a83df-eaa2-4ca5-eff8-abfb48832017"
   },
   "outputs": [],
   "source": [
    "edge_attrs = model.spherical_harmonics(points)\n",
    "print(\"shape:\", edge_attrs.shape)\n",
    "print(\"number of edges:\", edge_attrs.shape[0])\n",
    "print(\"number of features: (2l + 1)^2=\", edge_attrs.shape[1])\n",
    "\n",
    "# Compute the norm of the different irreps of the spherical harmonics for the first edge\n",
    "norm_0 = edge_attrs[0, 0].norm() ** 2\n",
    "print(\"norm of the 0th irrep: 2*0 + 1 =\", int(np.round(norm_0.item())))\n",
    "norm_1 = edge_attrs[0, 1:4].norm() ** 2\n",
    "print(\"norm of the 1st irrep: 2*1 + 1 =\", int(np.round(norm_1.item())))\n",
    "norm_2 = edge_attrs[0, 4:9].norm() ** 2\n",
    "print(\"norm of the 2nd irrep: 2*2 + 1 =\", int(np.round(norm_2.item())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD1Uecaskv8Y"
   },
   "source": [
    "The spherical harmonics evaluated this way are stored as edge attributes and will be used in the interaction block to compute the 1-particle basis and the message. Below is the relevant code snippet for the example water config to compute $Y^{m_{1}}_{l_{1}} (\\boldsymbol{\\hat{r}}_{ij})$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbijRy36pWpn",
    "outputId": "9a314ce1-57aa-4422-b87c-4f1ba2f1b3e9"
   },
   "outputs": [],
   "source": [
    "vectors, lengths = modules.utils.get_edge_vectors_and_lengths(\n",
    "            positions=batch[\"positions\"],\n",
    "            edge_index=batch[\"edge_index\"],\n",
    "            shifts=batch[\"shifts\"],\n",
    "        )\n",
    "edge_attrs = model.spherical_harmonics(vectors)\n",
    "print(f\"The edge attributes have shape (num_edges, num_spherical_harmonics)\\n\", edge_attrs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSAXaJeWn5Yr"
   },
   "source": [
    "### Radial Basis\n",
    "The edge features are scalars, typically 8 Bessel basis functions evaluated on the distance between the atoms. They are implemented in `mace/modules/radial.py`:\n",
    "\n",
    "```py\n",
    "class BesselBasis(torch.nn.Module)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6SFhHbfoEgE",
    "outputId": "75a77cda-c23b-4a66-93cd-7ece2223e117"
   },
   "outputs": [],
   "source": [
    "model.radial_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AN0fSflo69G"
   },
   "source": [
    "This implements the following basis functions:\n",
    "\n",
    "$j^{n}_{0} (r_{ij}) =  \\sqrt{\\frac{2}{r_{\\text{cut}}}} \\frac{\\sin{\\left(n\\pi\\frac{r_{ij}}{r_{\\text{cut}}} \\right)}}{r_{ij}} f_{\\text{cut}}(r_{ij})$\n",
    "\n",
    "We can plot the 8 Bessel basis functions corresponding to $n=0$ to $n=7$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "XW6RMXMyo3q8",
    "outputId": "69ece1c3-57ea-4c81-d9f2-1d7646d674d3"
   },
   "outputs": [],
   "source": [
    "dists = torch.tensor(np.linspace(0.1, 5.5, 100), dtype=torch.get_default_dtype()).unsqueeze(-1)\n",
    "\n",
    "radials = model.radial_embedding(dists)\n",
    "\n",
    "for i in range(radials.shape[1]):\n",
    "    plt.plot(dists, radials[:, i], label=f'Radial {i}')\n",
    "\n",
    "# Add title, labels, and legend\n",
    "plt.title(\"8 Bessel basis functions\")\n",
    "plt.xlabel(\"distance / A\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ccUbfMrk8m4"
   },
   "source": [
    "The radial basis is evaluated on the distances and is stored as edge features to be used later in the interaction block to compute the 1-particle basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ClKzTWYoMgs",
    "outputId": "8b834f89-8e35-478c-9c39-1228a4d22321"
   },
   "outputs": [],
   "source": [
    "edge_feats = model.radial_embedding(lengths)\n",
    "print(\"The edge features have shape (num_edges, num_radials)\")\n",
    "print(edge_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF9RrVF_qsks"
   },
   "source": [
    "### Node Embedding\n",
    "Next we look at the `LinearNodeEmbeddingBlock` implemented in `mace/modules/blocks.py`\n",
    "\n",
    "```py\n",
    "class LinearNodeEmbeddingBlock(torch.nn.Module):\n",
    "```\n",
    "\n",
    "The node attributes are integers that correspond to the chemical elements. They are prepared during the data loading (input preparation) phase using the `z_table` specifying the model chemical elements. This is part of creating the batch object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5vK-Bmsp3xV",
    "outputId": "c7e71bd4-4bd9-484b-cf93-85853602800a"
   },
   "outputs": [],
   "source": [
    "atomic_numbers = [8, 1, 1]  # the atomic numbers of the structure evaluated\n",
    "indices = tools.utils.atomic_numbers_to_indices(atomic_numbers, z_table=z_table)\n",
    "node_attrs = tools.torch_tools.to_one_hot(\n",
    "            torch.tensor(indices, dtype=torch.long).unsqueeze(-1),\n",
    "            num_classes=len(z_table),\n",
    "        )\n",
    "print(node_attrs)  # node attributes are the one hot encoding of the chemical  elements of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3phs2Ahrunj",
    "outputId": "f01d07c7-8c51-43b6-8d94-98ba34ee1f80"
   },
   "outputs": [],
   "source": [
    "model.node_embedding  # node embedding block of the model mapping the one-hot (2 dimensional because we have two chemical elements) to 32 channels using a learnable linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ped4DMZCuB5B",
    "outputId": "6203f264-31f5-4acf-c300-86c3f88fb7b1"
   },
   "outputs": [],
   "source": [
    "print(\"Weights are internally flattened and have a shape\",\n",
    "      model.node_embedding.linear.__dict__['_parameters']['weight'].shape)\n",
    "\n",
    "print(\"\\nThis corresponds to (num_chemical_elements, num_channels) learnable embeddings for each chemical element with shape:\",\n",
    "      model.node_embedding.linear.__dict__['_parameters']['weight'].reshape((2, 32)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p22YygT0jxTZ"
   },
   "source": [
    "Next is the implementation of forming the intial node embeddings:\n",
    "\n",
    " $h_{i,k00}^{(0)} = \\sum_z W_{kz} \\delta_{zz_{i}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ej5LV-C4s8T8",
    "outputId": "c9dce182-47bf-43f2-b94a-a70f2723777b"
   },
   "outputs": [],
   "source": [
    "# In MACE we create the initial node features using this block:\n",
    "node_feats = model.node_embedding(node_attrs)\n",
    "\n",
    "# chemical elements are embedded into 32 channels of the model. These 32 numbers are the initial node features.\n",
    "print(\"The node embedding block returns (num_atoms, num_channels) shaped tensor:\", node_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CD3JY4gUlG08"
   },
   "source": [
    "These initial node features will be used in the 1-particle basis of the interaction block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap7oQ5gBtDsi"
   },
   "source": [
    "## Interaction Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xS9IuG-ntH20"
   },
   "source": [
    "The interaction blocks is used to create the **sketched** atomic basis $A_{iklm}$ for each atoms $i$ at each layer $s$.\n",
    "Different interaction blocks can be used, but the two defaults are the   **RealAgnosticInteractionBlock** for the first layer and **RealAgnosticResidualInteractionBlock** implemented in `mace/modules/blocks.py`.\n",
    "```py\n",
    "class RealAgnosticResidualInteractionBlock()\n",
    "```\n",
    "Here we will analyse the interaction block used in the model at the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdTu05QntLga",
    "outputId": "17de8187-b2d0-4081-f299-068749d48361"
   },
   "outputs": [],
   "source": [
    "print(model.interactions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mp5_V9StNrv"
   },
   "source": [
    "It has four steps:\n",
    "1. Linearly mixing the incoming node features: $\\bar{h}^{(s)}_{i,kl_2m_2} = \\sum_{\\tilde{k}} W_{k\\tilde{k}l_2}^{(s)} h^{(s)}_{i,\\tilde{k}l_2m_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDg2x6xqtPaq",
    "outputId": "d0ceea64-593f-41a6-ab54-be0173bbbf91"
   },
   "outputs": [],
   "source": [
    "print(model.interactions[0].linear_up)\n",
    "node_feats = model.interactions[0].linear_up(node_feats)\n",
    "print(node_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W68Wdkr6tR1J"
   },
   "source": [
    "2. Construct the learnable radial basis using the Bessel Basis and the radial **MLP**:\n",
    "$    R_{k \\eta_{1} l_{1}l_{2} l_{3}}^{(s)}(r_{ij}) =   {\\rm MLP}\\left( \\left\\{ {j_0^n} (r_{ij})\\right\\}_{n}\\right)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1qcJPa3tTq-",
    "outputId": "7e9964ab-35ca-4397-d867-80dc75337985"
   },
   "outputs": [],
   "source": [
    "print(model.interactions[0].conv_tp_weights)\n",
    "# We go from 8 Bessel channels, to three layers of 64 channels, to 224 channels representing all the paths in the tensor product of the two irreps\n",
    "tp_weights = model.interactions[0].conv_tp_weights(edge_feats)\n",
    "print(tp_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9ccbJjpzId2"
   },
   "source": [
    "At this point it is possible to plot the MACE learnt radial functions (Note that here the model is untrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "R9i6tY8zzH-9",
    "outputId": "fdfda313-7d84-4e7f-af87-f6c6b76b39da"
   },
   "outputs": [],
   "source": [
    "dists = torch.tensor(np.linspace(0.1, 5.5, 100), dtype=torch.get_default_dtype()).unsqueeze(-1)\n",
    "\n",
    "edge_feats_scan = model.radial_embedding(dists)\n",
    "\n",
    "tp_weights_scan = model.interactions[0].conv_tp_weights(edge_feats_scan).detach().numpy()\n",
    "\n",
    "num_basis_to_print = 5\n",
    "for i in range(num_basis_to_print):\n",
    "    plt.plot(dists, tp_weights_scan[:, i], label=f'Learnable Radial {i}')\n",
    "\n",
    "# Add title, labels, and legend\n",
    "plt.title(\"MACE learnable radial functions (untrained)\")\n",
    "plt.xlabel(\"distance / A\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-6LUzC0tYVi"
   },
   "source": [
    "3. The formation of the one particle basis  $\\phi_{ij,k \\eta_{1} l_{3}m_{3}}^{(s)} = \\sum_{l_1l_2m_1m_2} C_{\\eta_1,l_1m_1l_2m_2}^{l_3m_3}R_{k \\eta_{1}l_{1}l_{2}l_{3}}^{(s)}(r_{ij})  Y^{m_{1}}_{l_{1}} (\\boldsymbol{\\hat{r}}_{ij}) \\bar{h}^{(s)}_{j,kl_2m_2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCRackfgtbhR",
    "outputId": "9fa2a9a5-6736-4cb7-b422-bfdada9f3dd6"
   },
   "outputs": [],
   "source": [
    "print(model.interactions[0].conv_tp)\n",
    "sender, receiver = batch[\"edge_index\"] # use the graph to get the sender and receiver indices\n",
    "mji = model.interactions[0].conv_tp(\n",
    "            node_feats[sender], edge_attrs, tp_weights\n",
    "        )\n",
    "print(\"The first dimension is the number of edges, highlighted by the ij in the variable name\", mji.shape)\n",
    "print(f\"The second dimension is num_channels * num_paths dimensional * (l3 + 1)**2, in this case: {mji.shape[-1]} = 32 * {tp_weights.shape[-1] // 32} * 9 \", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bm7BqoAwteUF"
   },
   "source": [
    "4. The sum over the neighbors of atom $i$ to form the atomic basis $\\sum_{j \\in \\mathcal{N}(i)} \\phi_{ij,k \\eta_{1} l_{3}m_{3}}^{(s)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-BPSmn1tf0X",
    "outputId": "d850a68d-e244-4284-c99b-ade13b9932d7"
   },
   "outputs": [],
   "source": [
    "from mace.tools.scatter import scatter_sum\n",
    "message = scatter_sum(\n",
    "            src=mji, index=receiver, dim=0, dim_size=node_feats.shape[0]\n",
    "        )\n",
    "print(\"The messages have first dimension corresponding to the nodes i:\", message.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iW8Bvy5xthbC"
   },
   "source": [
    "5. The linear sketching that mixes the channels to form  $A_{i,kl_{3}m_{3}}^{(s)} = \\sum_{\\tilde{k}, \\eta_{1}} W_{k \\tilde{k} \\eta_{1}l_{3}}^{(s)}\\sum_{j \\in \\mathcal{N}(i)}  \\phi_{ij,\\tilde{k} \\eta_{1} l_{3}m_{3}}^{(s)}$.\n",
    "    \n",
    "    For the first layer **only**, these weights are species dependent (hence the last module called skip_tp) but we will show the default case here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNElvNgXtjWq",
    "outputId": "c82c396b-6064-4b32-d596-a1582ff129ea"
   },
   "outputs": [],
   "source": [
    "node_feats = model.interactions[0].linear(message)\n",
    "print(\"This step leaves the shape unchanged:\", message.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmGGL4CR356N"
   },
   "source": [
    "## Equivariant Symmetric Product Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8Z46jWl36-Z"
   },
   "source": [
    "$$  {m}_i^{(t)} =\n",
    "  \\sum_j {u}_1 \\left( \\sigma_i^{(t)}; \\sigma_j^{(t)} \\right)\n",
    "  + \\sum_{j_1, j_2} {u}_2 \\left(\\sigma_i^{(t)}; \\sigma_{j_1}^{(t)}, \\sigma_{j_2}^{(t)} \\right)\n",
    "  + \\dots +\n",
    "  \\sum_{j_1, \\dots, j_{\\nu}} {u}_{\\nu} \\left( \\sigma_i^{(t)}; \\sigma_{j_1}^{(t)}, \\dots, \\sigma_{j_{\\nu}}^{(t)} \\right)$$\n",
    "\n",
    "The equivariant symmetric product is implemented in `mace/modules/symmetric_contraction.py` and is called **SymmetricContraction**.\n",
    "\n",
    "```py\n",
    "class SymmetricContraction(CodeGenMixin, torch.nn.Module):\n",
    "```\n",
    "\n",
    "The key operation of MACE is the efficient construction of higher order features from the ${A}_{i}^{(t)}$-features.\n",
    "This is achieved by first forming tensor products of the features, and then symmetrising:\n",
    "\n",
    "$$\n",
    "  {B}^{(t)}_{i,\\eta_{\\nu} k LM}\n",
    "  = \\sum_{{l}{m}} \\mathcal{C}^{LM}_{\\eta_{\\nu}, l m} \\prod_{\\xi = 1}^{\\nu} A_{i,k l_\\xi  m_\\xi}^{(t)}, \\quad {l}{m} = (l_{1}m_{1},\\dots,l_{\\nu}m_{\\nu})\n",
    "  $$\n",
    "\n",
    "And then summing the basis with learnable weights to form the many body equivariant messages:\n",
    "\n",
    "$$m_{i,k LM}^{(t)} =  \\sum_{\\nu} \\sum_{\\eta_{\\nu}} W_{z_{i}k L, \\eta_{\\nu}}^{(t)} {B}^{(t)}_{i,\\eta_{\\nu} k LM}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3Srp18e4x95",
    "outputId": "56c12dd1-190b-4e08-8eda-da078df0431a"
   },
   "outputs": [],
   "source": [
    "print(model.products[0].symmetric_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vDZGMGp6H1l",
    "outputId": "813b5073-0c5b-412f-820d-bb14886d9018"
   },
   "outputs": [],
   "source": [
    "node_feats = model.interactions[0].reshape(message)\n",
    "print(\"Input shape\", node_feats.shape)\n",
    "node_feats = model.products[0](node_feats=node_feats, sc=None, node_attrs=batch[\"node_attrs\"])\n",
    "print(\"Output shape\", message.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_YiERWO44se"
   },
   "source": [
    "Each **Contraction** submodules of the **SymmetricContraction** module is responsible for the construction of the basis for a given equivariant output $LM$.\n",
    "One can print the shape of the different weights $W_{z_{i}k L, \\eta_{\\nu}}^{(t)}$ stored in this submodule. These weights have shape $[N_{\\text{elements}},N_{\\text{path}},N_{\\text{channels}}]$. The number $N_{\\text{path}}$ is a function of the output $LM$ and the correlation order $\\nu$, and $l_{\\text{max}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Mal7bBO43d4",
    "outputId": "78d70333-fd58-4af0-aba6-6683ecfdd33a"
   },
   "outputs": [],
   "source": [
    "print(\"nu = 3 :\",model.products[0].symmetric_contractions.contractions[0].__dict__[\"_parameters\"][\"weights_max\"].shape)\n",
    "print(\"nu = 2 :\",model.products[0].symmetric_contractions.contractions[0].weights[0].shape)\n",
    "print(\"nu = 1 :\",model.products[0].symmetric_contractions.contractions[0].weights[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLEKUdTLmL_A"
   },
   "source": [
    "## MACE readout\n",
    "\n",
    "To create the output of the model we use the node features from all layers $s$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathcal{R}^{(s)} \\left( \\boldsymbol{h}_i^{(s)} \\right) =\n",
    "    \\begin{cases}\n",
    "      \\sum_{k}W^{(s)}_{k}h^{(s)}_{i,k00}     & \\text{if} \\;\\; 1 < s < S \\\\[13pt]\n",
    "      {\\rm MLP} \\left( \\left\\{ h^{(s)}_{i,k00} \\right\\}_k \\right)  &\\text{if} \\;\\; s = S\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "The first linear readout is implemented in\n",
    "\n",
    "```py\n",
    "class LinearReadoutBlock(torch.nn.Module):\n",
    "```\n",
    "\n",
    "In our example case this maps the 32 dimensional $h^{(1)}_{i,k00}$, the invariant part os the node features after the first interaction to the first term in the aotmic site energy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnE_QfoQmwqH",
    "outputId": "7f0e656b-1d3b-4aaa-a1bb-7519703b2889"
   },
   "outputs": [],
   "source": [
    "print(model.readouts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZV78b7K2Pr9"
   },
   "outputs": [],
   "source": [
    "node_energies = model.readouts[0](node_feats).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_v0FAoantnw"
   },
   "source": [
    "The last layer readout block is a 1 hidden layer Multi Layer Percptron (MLP):\n",
    "\n",
    "```py\n",
    "class NonLinearReadoutBlock(torch.nn.Module):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vn2_Pxsbm3-X",
    "outputId": "660301d1-a2d7-49ee-a99b-48e64205d265"
   },
   "outputs": [],
   "source": [
    "print(model.readouts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mw4xGbV90-0A"
   },
   "source": [
    "It is also possible to have equivariant readouts. This can be achieved by using Gated non-linearities. See as an example:\n",
    "\n",
    "```py\n",
    "class NonLinearDipoleReadoutBlock(torch.nn.Module):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHi40bVa1k7b"
   },
   "source": [
    "These readouts are formed for each node in the batch. To turn them into a graph level readout we use a scatter sum operation which sums the node energies for each graph (separate chemical strucutre) in the batch. This is followed by summing the atomic energy and 1-st, 2nd etc. layer contributions to form the final model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGpLz7gXzAz0",
    "outputId": "0f4e8065-46cb-43c3-bd7c-bc2c2698913f"
   },
   "outputs": [],
   "source": [
    "# energy = scatter_sum(\n",
    "#                 src=node_energies, index=batch[\"batch\"], dim=-1, dim_size=batch.num_graphs\n",
    "#             )  # [n_graphs,]\n",
    "# # in the code this step is done for each layer followed by summing the layer-wise output\n",
    "# print(\"Energy:\",energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.cell"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
